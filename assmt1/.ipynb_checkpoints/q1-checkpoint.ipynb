{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import keyboard\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import depthai as dai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect 10 images from OAKD-lite \n",
    "# mention which camera to use to take the images (default = right)\n",
    "# params :\n",
    "#     src : [\"left\", \"right\"]\n",
    "\n",
    "\n",
    "def getImages(src=\"right\"):\n",
    "\n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - mono (grayscale) camera\n",
    "    cam = pipeline.createMonoCamera()\n",
    "    cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    cam.setResolution(dai.MonoCameraProperties.SensorResolution.THE_720_P)\n",
    "\n",
    "    # Create output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(src)\n",
    "    cam.out.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline) as device:\n",
    "\n",
    "        # Output queue will be used to get the grayscale frames from the output defined above\n",
    "        q = device.getOutputQueue(name=src, maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path('images/'+src+'/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(20):\n",
    "            inSrc = q.get()  # Blocking call, will wait until a new data has arrived\n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            cv.imshow(src, frame)\n",
    "            # After showing the frame, it's being stored inside a target directory as a PNG image\n",
    "            cv.imwrite(f\"07_data/\"+src+\"/{int(time.time() * 10000)}.png\", frame)\n",
    "\n",
    "            if cv.waitKey(1) == ord('q'):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18443010E181B60F00] [107.025] [MonoCamera(0)] [error] OV7251 only supports THE_480_P/THE_400_P resolutions, defaulting to THE_480_P\n"
     ]
    }
   ],
   "source": [
    "getImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'right'\n",
    "\n",
    "# Start defining a pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define a source - mono (grayscale) camera\n",
    "camRight = pipeline.createMonoCamera()\n",
    "if src == 'right' :\n",
    "    camRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "else :\n",
    "    camRight.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    \n",
    "camRight.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "# Create output\n",
    "xoutRight = pipeline.createXLinkOut()\n",
    "xoutRight.setStreamName(src)\n",
    "camRight.out.link(xoutRight.input)\n",
    "\n",
    "# Connect and start the pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "\n",
    "    # Output queue will be used to get the grayscale frames from the output defined above\n",
    "    qRight = device.getOutputQueue(name=src, maxSize=4, blocking=False)\n",
    "\n",
    "    # Make sure the destination path is present before starting to store the examples\n",
    "    Path('07_data/right').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        inRight = qRight.get()  # Blocking call, will wait until a new data has arrived\n",
    "        # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "        frameRight = inRight.getCvFrame()\n",
    "        # Frame is transformed and ready to be shown\n",
    "        cv.imshow(src, frameRight)\n",
    "        \n",
    "        cv.imwrite(f\"07_data/right/{int(time.time() * 10000)}.png\", frameRight)\n",
    "        cv.waitKey(1000)  \n",
    "            \n",
    "        cv.destroyAllWindows()            \n",
    "\n",
    "        \n",
    "################## CAPTURE BUTTON DIDNT WORK ################\n",
    "\n",
    "#         # press spacebar to capture\n",
    "#         if keyboard.is_pressed(\" \"):\n",
    "#             cv.destroyAllWindows()\n",
    "            \n",
    "#             cv.imshow(\"right\", frameRight)\n",
    "#             cv.imwrite(f\"07_data/right/{int(time.time() * 10000)}.png\", frameRight)\n",
    "#             cv.waitKey(500)\n",
    "            \n",
    "#             cv.destroyAllWindows()\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "\n",
    "objp = np.zeros((8*10,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:10,0:8].T.reshape(-1,2)\n",
    "\n",
    "# objp = np.zeros((6*7,3), np.float32)\n",
    "# objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/chessboard_8x10.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob.glob('images/*8x10.png')\n",
    "# images = glob.glob('images/*.jpg')\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (10,8), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (10,8), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "    else :\n",
    "        print('not found')\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "# for fname in images:\n",
    "#     img = cv.imread(fname)\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     # Find the chess board corners\n",
    "#     ret, corners = cv.findChessboardCorners(gray, (7,6), None)\n",
    "#     # If found, add object points, image points (after refining them)\n",
    "#     if ret == True:\n",
    "#         objpoints.append(objp)\n",
    "#         corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "#         imgpoints.append(corners)\n",
    "#         # Draw and display the corners\n",
    "#         cv.drawChessboardCorners(img, (7,6), corners2, ret)\n",
    "#         cv.imshow('img', img)\n",
    "#         cv.waitKey(5000)\n",
    "#     else :\n",
    "#         print('not found')\n",
    "\n",
    "\n",
    "# cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
